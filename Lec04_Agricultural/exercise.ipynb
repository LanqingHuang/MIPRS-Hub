{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## METHODOLOGIES FOR IMAGE PROCESSING OF REMOTE SENSING DATA\n",
    "## Lecture: monitoring rice\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP1: Reading & visualizing data files\n",
    "\n",
    "# this is the function to read the binary data\n",
    "def LoadESAR_noheader(path, name, DIM):\n",
    "    F1 = path + name\n",
    "    size_r, size_a = DIM[0], DIM[1]\n",
    "    with open(F1, 'rb') as f:\n",
    "        data = np.fromfile(f, count=2 * size_r * size_a, dtype='<f4')  # Adjust dtype based on your datatype\n",
    "\n",
    "    data = data.reshape(size_r * size_a, 2)\n",
    "    D = data[:, 0] + 1j * data[:, 1]\n",
    "    image = D.reshape(size_a, size_r)\n",
    "    image = np.transpose(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Define the path and file names\n",
    "Path = './'\n",
    "NameHH1 = 'HH5.dat'\n",
    "NameVV1 = 'VV5.dat'\n",
    "NameHH2 = 'HH7.dat'\n",
    "NameVV2 = 'VV7.dat'\n",
    "NameHH3 = 'HH9.dat'\n",
    "NameVV3 = 'VV9.dat'\n",
    "\n",
    "# Load images\n",
    "DIM = (1000, 1300)\n",
    "HH1 = LoadESAR_noheader(Path, NameHH1, DIM)\n",
    "VV1 = LoadESAR_noheader(Path, NameVV1, DIM)\n",
    "HH2 = LoadESAR_noheader(Path, NameHH2, DIM)\n",
    "VV2 = LoadESAR_noheader(Path, NameVV2, DIM)\n",
    "HH3 = LoadESAR_noheader(Path, NameHH3, DIM)\n",
    "VV3 = LoadESAR_noheader(Path, NameVV3, DIM)\n",
    "\n",
    "# visualize images\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot the images in subfigures\n",
    "img1 = axs[0].imshow(np.abs(HH1), cmap='gray', vmin=0, vmax=2.5 * np.mean(np.abs(HH1)))\n",
    "axs[0].set_title('Total image 1 in HH')\n",
    "axs[0].axis('off')\n",
    "fig.colorbar(img1, ax=axs[0])\n",
    "\n",
    "img2 = axs[1].imshow(np.abs(HH2), cmap='gray', vmin=0, vmax=2.5 * np.mean(np.abs(HH2)))\n",
    "axs[1].set_title('Total image 2 in HH')\n",
    "axs[1].axis('off')\n",
    "fig.colorbar(img2, ax=axs[1])\n",
    "\n",
    "img3 = axs[2].imshow(np.abs(HH3), cmap='gray', vmin=0, vmax=2.5 * np.mean(np.abs(HH3)))\n",
    "axs[2].set_title('Total image 3 in HH')\n",
    "axs[2].axis('off')\n",
    "fig.colorbar(img3, ax=axs[2])\n",
    "\n",
    "#plt.savefig('your/output/folder/input_data.png', bbox_inches='tight') # you can save the figure if you want\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP2: Building elements of the pauli vector, coherency & covariance matrix.\n",
    "\n",
    "First, Build the first two Pauli elements\n",
    "\n",
    "Please note the notation Notation: \n",
    "k1a: \"k\" refers to the scattering vector, \"1\" refers to scene # 1, and\n",
    "\"a\" refers to the first element in the vector.\n",
    "\n",
    "Try to figure fill the blank ('quiz') part by yourself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## STEP2: Building elements of the pauli vector, coherency & covariance matrix\n",
    "from scipy.signal import convolve as scipy_convolve\n",
    "\n",
    "# Build the two Pauli components\n",
    "k1a = 1 / np.sqrt(2) * (HH1 + VV1)\n",
    "k1b = 1 / np.sqrt(2) * (HH1 - VV1)\n",
    "k2a = quiz  #think about how to calculate k2a\n",
    "k2b = quiz\n",
    "k3a = quiz\n",
    "k3b = quiz\n",
    "\n",
    "# Prepare the window for filtering\n",
    "sw = (quiz, quiz) #you can set your own window size for filtering, e.g. 5by5,9by9   \n",
    "H = np.ones(sw) / (sw[0] * sw[1])  # Create an average filter kernel\n",
    "\n",
    "# Create the Coherency matrix\n",
    "T1aa = scipy_convolve(np.abs(k1a) ** 2, H, mode='same', method='direct')\n",
    "T1bb = scipy_convolve(np.abs(k1b) ** 2, H, mode='same', method='direct')\n",
    "T1ab = scipy_convolve(k1a * np.conj(k1b), H, mode='same', method='direct')\n",
    "\n",
    "T2aa = scipy_convolve(np.abs(k2a) ** 2, H, mode='same', method='direct')\n",
    "T2bb = quiz\n",
    "T2ab = quiz\n",
    "\n",
    "T3aa = quiz\n",
    "T3bb = quiz\n",
    "T3ab = quiz\n",
    "\n",
    "# Create the Covariance matrix in Lexicographic basis\n",
    "C1aa = scipy_convolve(np.abs(HH1) ** 2, H, mode='same', method='direct')\n",
    "C1bb = scipy_convolve(np.abs(VV1) ** 2, H, mode='same', method='direct')\n",
    "C1ab = scipy_convolve(HH1 * np.conj(VV1), H, mode='same', method='direct')\n",
    "\n",
    "C2aa = scipy_convolve(np.abs(HH2) ** 2, H, mode='same', method='direct')\n",
    "C2bb = quiz\n",
    "C2ab = quiz\n",
    "\n",
    "C3aa = quiz\n",
    "C3bb = quiz\n",
    "C3ab = quiz\n",
    "\n",
    "print('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP3: Visualize the modified Pauli RGB\n",
    "\n",
    "i1b = T1aa / (1.5 * np.mean(np.mean(T1aa + T1bb)))\n",
    "i1r = T1bb / (1.5 * np.mean(np.mean(T1aa + T1bb)))\n",
    "i1g = np.abs(C1ab)\n",
    "rgb1Image = np.zeros((dimr, dima, 3))\n",
    "rgb1Image[:, :, 0] = np.abs(i1r)\n",
    "rgb1Image[:, :, 2] = np.abs(i1b)\n",
    "rgb1Image[:, :, 1] = np.abs(i1g)\n",
    "\n",
    "i2b = T2aa / (1.5 * np.mean(np.mean(T2aa + T2bb)))\n",
    "i2r = T2bb / (1.5 * np.mean(np.mean(T2aa + T2bb)))\n",
    "i2g = np.abs(C2ab)\n",
    "rgb2Image = np.zeros((dimr, dima, 3))\n",
    "rgb2Image[:, :, 0] = np.abs(i2r)\n",
    "rgb2Image[:, :, 2] = np.abs(i2b)\n",
    "rgb2Image[:, :, 1] = np.abs(i2g)\n",
    "\n",
    "i3b = T3aa / (1.5 * np.mean(np.mean(T3aa + T3bb)))\n",
    "i3r = T3bb / (1.5 * np.mean(np.mean(T3aa + T3bb)))\n",
    "i3g = np.abs(C3ab)\n",
    "rgb3Image = np.zeros((dimr, dima, 3))\n",
    "rgb3Image[:, :, 0] = np.abs(i3r)\n",
    "rgb3Image[:, :, 2] = np.abs(i3b)\n",
    "rgb3Image[:, :, 1] = np.abs(i3g)\n",
    "\n",
    "# visualize images\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot the images in subfigures\n",
    "img1 = axs[0].imshow(rgb1Image)\n",
    "axs[0].set_title('RGB Pauli with boxcar: Scene 1')\n",
    "axs[0].axis('off')\n",
    "\n",
    "img2 = axs[1].imshow(rgb2Image)\n",
    "axs[1].set_title('RGB Pauli with boxcar: Scene 2')\n",
    "axs[1].axis('off')\n",
    "\n",
    "img3 = axs[2].imshow(rgb3Image)\n",
    "axs[2].set_title('RGB Pauli with boxcar: Scene 3')\n",
    "axs[2].axis('off')\n",
    "\n",
    "# Save the figure\n",
    "#plt.savefig('subfigures_rgb_scenes.png', bbox_inches='tight') # you can save the figure if you want\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will calculate polarimetric observables for each scene. Check the equations from the slide to fill the quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Polarimetric observables for scene 1--------\n",
    "# Observables with ratios: Lexicographic\n",
    "Ratio1VVHH = C1bb / C1aa #hint: choose quiz from C1aa C1bb C1ab\n",
    "\n",
    "# Observables with ratios: Pauli\n",
    "Ratio1ab = quiz/quiz #hint: choose quiz from T1aa T1bb T1ab\n",
    "\n",
    "# Observables with coherences\n",
    "Cohe1HHVV = C1ab / np.sqrt(quiz * quiz) #hint: choose quiz from C1aa C1bb C1ab\n",
    "\n",
    "\n",
    "#---Polarimetric observables for scene 2--------\n",
    "# Observables with ratios: Lexicographic\n",
    "Ratio2VVHH = quiz\n",
    "\n",
    "# Observables with ratios: Pauli\n",
    "Ratio2ab = quiz\n",
    "\n",
    "# Observables with coherences\n",
    "Cohe2HHVV = quiz\n",
    "\n",
    "\n",
    "#---Polarimetric observables for scene 3--------\n",
    "# Observables with ratios: Lexicographic\n",
    "Ratio3VVHH = quiz\n",
    "\n",
    "# Observables with ratios: Pauli\n",
    "Ratio3ab = quiz\n",
    "\n",
    "# Observables with coherences\n",
    "Cohe3HHVV = quiz\n",
    "\n",
    "# Now, let's visualize the polarimetric observables in subfigures\n",
    "fig, axs = plt.subplots(3, 4, figsize=(15, 15))\n",
    "\n",
    "# Function to plot images in subfigures\n",
    "def plot_image(ax, image, title, vmin=None, vmax=None):\n",
    "    im = ax.imshow(image, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(title,fontsize=10)\n",
    "    ax.axis('off')\n",
    "    return im\n",
    "\n",
    "# Visualize the Ratios and Coherences for each scene\n",
    "scenes = ['Scene 1', 'Scene 2', 'Scene 3']\n",
    "ratios = [Ratio1VVHH, Ratio2VVHH, Ratio3VVHH]\n",
    "surface_ratios = [Ratio1ab, Ratio2ab, Ratio3ab]\n",
    "coherences_magnitude = [np.abs(Cohe1HHVV), np.abs(Cohe2HHVV), np.abs(Cohe3HHVV)]\n",
    "coherences_phase = [np.angle(Cohe1HHVV), np.angle(Cohe2HHVV), np.angle(Cohe3HHVV)]\n",
    "\n",
    "for i, scene in enumerate(scenes):\n",
    "    row = i\n",
    "    im1 = plot_image(axs[row, 0], ratios[i], f'Ratio VV over HH: {scene}',vmin=0, vmax=2.5 * np.mean(np.mean(ratios[i])))\n",
    "    im2 = plot_image(axs[row, 1], surface_ratios[i], f'Ratio Surface over horizontal Dihedral',vmin=0, vmax=2.5 * np.mean(np.mean(surface_ratios[i])))\n",
    "    im3 = plot_image(axs[row, 2], coherences_magnitude[i], f'Magnitude of coherence between HH and VV',vmin=0, vmax=1)\n",
    "    im4 = plot_image(axs[row, 3], coherences_phase[i], f'Phase of coherence between HH and VV',vmin=-np.pi, vmax=np.pi)\n",
    "\n",
    "# Save the figure\n",
    "#plt.savefig('subfigures_ratios_coherences.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP4: Region of Interest (ROI) analysis\n",
    "# Define the ROI coordinates. YOU can select an area (ROI) inside one single field to analyse: it is important \n",
    "# that the ROI is as large as possible, but it only includes pixels from one single field\n",
    "rg_start = 400\n",
    "rg_end = 500\n",
    "az_start = 200\n",
    "az_end = 300\n",
    "\n",
    "# Ensure that the area is contained in one field\n",
    "Test_Area = C1aa.copy()\n",
    "Test_Area[rg_start:rg_end, az_start:az_end] = np.mean(np.mean(C1aa))\n",
    "plt.figure()\n",
    "plt.imshow(Test_Area, cmap='gray', vmin=0, vmax=2.5 * np.mean(np.mean(C1aa)))\n",
    "plt.title('Select test area with HH intensity')\n",
    "\n",
    "# Plot the trends: we want to extract the mean value of the polarimetric obsevable inside the ROI.\n",
    "# First Acquisition:\n",
    "Av_Ratio1VVHH = np.mean(np.mean(Ratio1VVHH[rg_start:rg_end, az_start:az_end]))\n",
    "Av_Ratio1ab = np.mean(np.mean(Ratio1ab[rg_start:rg_end, az_start:az_end]))\n",
    "Av_Cohe1HHVV = np.mean(np.mean(Cohe1HHVV[rg_start:rg_end, az_start:az_end]))\n",
    "\n",
    "# Second Acquisition:\n",
    "Av_Ratio2VVHH = np.mean(np.mean(Ratio2VVHH[rg_start:rg_end, az_start:az_end]))\n",
    "Av_Ratio2ab = np.mean(np.mean(Ratio2ab[rg_start:rg_end, az_start:az_end]))\n",
    "Av_Cohe2HHVV = np.mean(np.mean(Cohe2HHVV[rg_start:rg_end, az_start:az_end]))\n",
    "\n",
    "# Third Acquisition:\n",
    "Av_Ratio3VVHH = np.mean(np.mean(Ratio3VVHH[rg_start:rg_end, az_start:az_end]))\n",
    "Av_Ratio3ab = np.mean(np.mean(Ratio3ab[rg_start:rg_end, az_start:az_end]))\n",
    "Av_Cohe3HHVV = np.mean(np.mean(Cohe3HHVV[rg_start:rg_end, az_start:az_end]))\n",
    "\n",
    "# Create the trends arrays\n",
    "Trend_RatioVVHH = [Av_Ratio1VVHH, Av_Ratio2VVHH, Av_Ratio3VVHH]\n",
    "Trend_Ratioab = [Av_Ratio1ab, Av_Ratio2ab, Av_Ratio3ab]\n",
    "Trend_CoheHHVV = [Av_Cohe1HHVV, Av_Cohe2HHVV, Av_Cohe3HHVV]\n",
    "\n",
    "scene_labels = [\"Scene 1\", \"Scene 2\", \"Scene 3\"]\n",
    "\n",
    "# Plot the trends\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# Function to plot trends in subfigures\n",
    "def plot_trend(ax, trend, title, ylabel):\n",
    "    ax.plot(trend)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(3))\n",
    "    ax.set_xticklabels(scene_labels)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "# Plot the trends in subfigures\n",
    "plot_trend(axs[0, 0], Trend_RatioVVHH, 'Trend of Ratios: copol', 'Ratio VV over HH')\n",
    "plot_trend(axs[0, 1], Trend_Ratioab, 'Trend of Ratios: Pauli', 'Ratio Surface over horizontal Dihedral')\n",
    "plot_trend(axs[1, 0], np.abs(Trend_CoheHHVV), 'Trend of Coherences: magnitude', 'Magnitude')\n",
    "plot_trend(axs[1, 1], np.angle(Trend_CoheHHVV), 'Trend of Coherences: phase', 'Phase')\n",
    "\n",
    "# Save the figure\n",
    "#plt.savefig('subfigures_trends.png', bbox_inches='tight') # you can save the figure if you want\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIPRS_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
